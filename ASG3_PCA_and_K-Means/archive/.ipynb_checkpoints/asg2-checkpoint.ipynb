{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209535cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "debug = True                        # Displays additional logging output\n",
    "savePlots = False                   # Saves plot image files\n",
    "targetColumnName = \"TARGET\"         # Name for column denoting dependant variable\n",
    "outlierThreshold = 3                # Number of standard deviations from which data will be classified as an outlier\n",
    "dropMissingValues = True #Needs to be true for randomTreeRegressor\n",
    "\n",
    "# Various file names for debugging and analysis\n",
    "stringVariablesFile =           './outputFiles/stringVariables.txt'\n",
    "continuousVariablesFile =       './outputFiles/continuousVariables.txt'\n",
    "categoricalVariablesFile =      './outputFiles/categoricalVariables.txt'\n",
    "datasetName =                   './dataset/application_train.csv'\n",
    "initialDataFileName =           './outputFiles/initialData.txt'\n",
    "missingValFileName =            './outputFiles/missingValueSummary.txt'\n",
    "noMissingValuesFileName =       './outputFiles/noMissingValueSummary.txt'\n",
    "initialDistributionFileName =   './outputFiles/initialDistribution.txt'\n",
    "dataFrameFileName =             './outputFiles/dataFrameDebug.txt'\n",
    "generalDebugFileName =          './debug.txt'\n",
    "testFileName =                  './dataset/application_test.csv'\n",
    "\n",
    "# Chosen top 10 variables from ASG1\n",
    "# @TODO: figure out if we want to do a mixture of ext source variables\n",
    "# @todo: figure out if we want to remove target from these columns\n",
    "chosenTopTenVariables = ['TARGET', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'CODE_GENDER', 'EXT_SOURCE_1',\n",
    "                         'DAYS_BIRTH', 'CNT_CHILDREN', 'AMT_CREDIT', 'NAME_INCOME_TYPE',\n",
    "                         'NAME_EDUCATION_TYPE']\n",
    "\n",
    "forestTopTenVariables = ['EXT_SOURCE_3',\n",
    "                         'TARGET',\n",
    "'EXT_SOURCE_2',\n",
    "'EXT_SOURCE_1',\n",
    "'AMT_ANNUITY',\n",
    "'DAYS_EMPLOYED',\n",
    "'AMT_CREDIT',\n",
    "'DAYS_ID_PUBLISH',\n",
    "'DAYS_REGISTRATION',\n",
    "'LIVINGAREA_MODE',\n",
    "'AMT_GOODS_PRICE',\n",
    "]\n",
    "#, 'ORGANIZATION_TYPE'*/]\n",
    "\n",
    "lineString = \"---------------------------------------------------------------------------------------------------------\"\n",
    "\n",
    "debugFd = open(generalDebugFileName, \"w+\")\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Global Variables Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13c9f7f-9248-447d-a522-de5f3b59344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Imports Cell Completed...\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Library Imports\n",
    "from nis import cat\n",
    "from re import X\n",
    "import pandas as pd                 # Used for data frame\n",
    "import plotly                       # Saves html plots\n",
    "import plotly.express as px         # Used for displaying plots\n",
    "import os                           # Allows file manipulation and console debugging for offline jupyter\n",
    "import numpy as np\n",
    "from scipy import stats             # Used for outliers\n",
    "import matplotlib.pyplot as plt     # Used for pyplot heatmap plotting\n",
    "import seaborn as sns               # Used for showing heatmap\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "    # Import the model we are using\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#@TODO: Figure out if we want to delete this or not and use the sklearn tree\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "import graphviz # Data Tree Visualization\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "import pickle                                   # Saving Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import graphviz # Data Tree Visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import pydot\n",
    "\n",
    "import phik\n",
    "\n",
    "from phik import resources\n",
    "from phik.binning import bin_data\n",
    "from phik.report import plot_correlation_matrix\n",
    "\n",
    "if debug == True:\n",
    "    print(\"Library Imports Cell Completed...\")\n",
    "    print(lineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16fd574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Imports\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Module Imports Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962cad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software configurations\n",
    "pd.options.display.max_rows = 4000  # Allows better debugging analysis\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Software Configuration Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7c79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# If the debugging flag is on, creates directories to store output data\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def createOutputDirectories(debug = False):\n",
    "    if debug == False:\n",
    "        return\n",
    "    if not os.path.exists(\"images\"):\n",
    "        os.mkdir(\"images\")\n",
    "    if not os.path.exists(\"images/initialPlots\"):\n",
    "        os.mkdir(\"images/initialPlots\")\n",
    "    if not os.path.exists(\"images/topTenPlots\"):\n",
    "        os.mkdir(\"images/topTenPlots\")\n",
    "    if not os.path.exists(\"outputFiles\"):\n",
    "        os.mkdir(\"outputFiles\")\n",
    "    print(\"createOutputDirectories...success\")\n",
    "\n",
    "\n",
    "# Reads csv file into data frame and sets independant and dependant variables\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param fileName: string for full relative file path of csv file\n",
    "# @param dependantVarColumnName: csv file column matching name of column for dependant variable\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# data: dataframe object of csv file reading\n",
    "# independantVars: independant variables (all data that isn't targetColumnName)\n",
    "# dependantVar: dependant variable\n",
    "#\n",
    "def readData(fileName, dependantVarColumnName = targetColumnName, debug = False):\n",
    "    independantVars = []\n",
    "    dependantVar = []\n",
    "    data = pd.read_csv(fileName)\n",
    "    index = None\n",
    "    for i ,col in enumerate(data.columns):\n",
    "        if col == dependantVarColumnName:\n",
    "            index = i\n",
    "    if index != None: \n",
    "        dependantVar = data.iloc[:, index]\n",
    "        independantVars = data.iloc[:]\n",
    "        independantVars.pop(dependantVarColumnName)\n",
    "    if debug:\n",
    "        fd = open(initialDataFileName, \"w+\")\n",
    "        fd.write(\"This file contains the initial data frame without cleaning:\\n\")\n",
    "        fd.write(str(data))\n",
    "        fd.close()\n",
    "        print(\"readData...completed\")\n",
    "    return data, independantVars, dependantVar\n",
    "\n",
    "\n",
    "# Drops rows from dataset which are missing. Prints missing value data for debugging\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to have missing values dropped and returned\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# data: dataframe object with missing values dropped\n",
    "#\n",
    "def dropMissingValues(data, debug = False):\n",
    "    # Drop missing values\n",
    "    ret = data.dropna(axis=0)\n",
    "    # Show number of missing values per independant variable\n",
    "    if debug:\n",
    "        fd = open(missingValFileName, \"w+\")\n",
    "        fd.write(\"This data shows the independant variables which contained missing values and the count of each:\\n\")\n",
    "        fd.write(str(data.isnull().sum()))\n",
    "        fd.close()\n",
    "        fd = open(noMissingValuesFileName, \"w+\")\n",
    "        fd.write(\"This data shows the independant variables which are used for analysis with no mising values:\\n\")\n",
    "        fd.write(str(ret.isnull().sum()))\n",
    "        fd.close()\n",
    "        print(\"dropMissingValues...completed\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "def setMeanValues(data, debug = False):\n",
    "    return data\n",
    "\n",
    "# Writes distribution of data frame to text file\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to have distribution written to text file\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def writeDistribution(data, debug = False):\n",
    "    if debug == False:\n",
    "        return\n",
    "    numpy_array = data.to_numpy()\n",
    "    fd = open(initialDistributionFileName, \"w+\")\n",
    "    fd.write(str(numpy_array))\n",
    "    fd.close()\n",
    "    print(\"writeDistribution...success\")\n",
    "\n",
    "\n",
    "def doBar(data, column_name, figsize = (18,6), \n",
    "          percentage_display = True,\n",
    "          plot_defaulter = True, rotation = 0, \n",
    "          horizontal_adjust = 0, \n",
    "          fontsize_percent = 'xx-small',\n",
    "          dirName = 'images/initialPlots/'):\n",
    "\n",
    "    \n",
    "    print(f\"Total Number of unique categories of {column_name} = {len(data[column_name].unique())}\")\n",
    "    \n",
    "    plt.figure(figsize = figsize, tight_layout = False)\n",
    "    sns.set(style = 'whitegrid', font_scale = 1.2)\n",
    "    \n",
    "    #plotting overall distribution of category\n",
    "    plt.subplot(1,2,1)\n",
    "    data_to_plot = data[column_name].value_counts().sort_values(ascending = False)\n",
    "    ax = sns.barplot(x = data_to_plot.index, y = data_to_plot, palette = 'Set1')\n",
    "    \n",
    "    if percentage_display:\n",
    "        total_datapoints = len(data[column_name].dropna())\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + horizontal_adjust, p.get_height() + 0.005 * total_datapoints, '{:1.02f}%'.format(p.get_height() * 100 / total_datapoints), fontsize = fontsize_percent)\n",
    "        \n",
    "    plt.xlabel(column_name, labelpad = 10)\n",
    "    plt.title(f'Distribution of {column_name}', pad = 20)\n",
    "    plt.xticks(rotation = rotation)\n",
    "    plt.ylabel('Counts')\n",
    "    \n",
    "    #plotting distribution of category for Defaulters\n",
    "    if plot_defaulter:\n",
    "        percentage_defaulter_per_category = (data[column_name][data.TARGET == 1].value_counts() * 100 / data[column_name].value_counts()).dropna().sort_values(ascending = False)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.barplot(x = percentage_defaulter_per_category.index, y = percentage_defaulter_per_category, palette = 'Set2')\n",
    "        plt.ylabel('Percentage of Defaulter per category')\n",
    "        plt.xlabel(column_name, labelpad = 10)\n",
    "        plt.xticks(rotation = rotation)\n",
    "        plt.title(f'Percentage of Defaulters for each category of {column_name}', pad = 20)\n",
    "\n",
    "    fileName = dirName + column_name + '.png'\n",
    "    plt.savefig(fileName)\n",
    "\n",
    "\n",
    "# Plots a column name of the dataframe and saves each plot into a file\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data:       dataframe to have distribution written to text file\n",
    "# @param plots:      types of plots for each column to show e.g. \"box\"\n",
    "# @param: figsize:   size of figure for matplotlib to plot\n",
    "# @param: log_scale: flag to log the scale of the plot\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def plot_column(data,\n",
    "                column_name,\n",
    "                plots = [],\n",
    "                figsize = (20,8),\n",
    "                log_scale = False,\n",
    "                dirName = 'images/initialPlots/'):\n",
    "\n",
    "    if 'bar' in plots:\n",
    "        doBar(data, column_name, figsize, dirName = dirName)\n",
    "        return\n",
    "    data_to_plot = data.copy()\n",
    "    plt.figure(figsize = figsize)\n",
    "    sns.set_style('whitegrid')\n",
    "    \n",
    "    for i, ele in enumerate(plots):\n",
    "        plt.subplot(1, len(plots), i + 1)\n",
    "        plt.subplots_adjust(wspace=0.25)\n",
    "        if ele == 'CDF':\n",
    "            #making the percentile DataFrame for both positive and negative Class Labels\n",
    "            percentile_values_0 = data_to_plot[data_to_plot.TARGET == 0][[column_name]].dropna().sort_values(by = column_name)\n",
    "            percentile_values_0['Percentile'] = [ele / (len(percentile_values_0)-1) for ele in range(len(percentile_values_0))]\n",
    "            \n",
    "            percentile_values_1 = data_to_plot[data_to_plot.TARGET == 1][[column_name]].dropna().sort_values(by = column_name)\n",
    "            percentile_values_1['Percentile'] = [ele / (len(percentile_values_1)-1) for ele in range(len(percentile_values_1))]\n",
    "            \n",
    "            plt.plot(percentile_values_0[column_name], percentile_values_0['Percentile'], color = 'red', label = 'Non-Defaulters')\n",
    "            plt.plot(percentile_values_1[column_name], percentile_values_1['Percentile'], color = 'black', label = 'Defaulters')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Probability')\n",
    "            plt.title('CDF of {}'.format(column_name))\n",
    "            plt.legend(fontsize = 'medium')\n",
    "            if log_scale:\n",
    "                plt.xscale('log')\n",
    "                plt.xlabel(column_name + ' - (log-scale)')\n",
    "        elif ele == 'distplot':\n",
    "            sns.distplot(data_to_plot[column_name][data['TARGET'] == 0].dropna(),\n",
    "                         label='Non-Defaulters', hist = False, color='red')\n",
    "            sns.distplot(data_to_plot[column_name][data['TARGET'] == 1].dropna(),\n",
    "                         label='Defaulters', hist = False, color='black')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Probability Density')\n",
    "            plt.legend(fontsize='medium')\n",
    "            plt.title(\"Dist-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.xscale('log')\n",
    "                plt.xlabel(f'{column_name} (log scale)')\n",
    "        elif ele == 'violin':  \n",
    "            sns.violinplot(x='TARGET', y=column_name, data=data_to_plot)\n",
    "            plt.title(\"Violin-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.yscale('log')\n",
    "                plt.ylabel(f'{column_name} (log Scale)')\n",
    "        elif ele == 'box':  \n",
    "            sns.boxplot(x='TARGET', y=column_name, data=data_to_plot)\n",
    "            plt.title(\"Box-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.yscale('log')\n",
    "                plt.ylabel(f'{column_name} (log Scale)')\n",
    "\n",
    "    fileName = dirName + column_name + '.png'\n",
    "    plt.savefig(fileName)\n",
    "\n",
    "\n",
    "def showTargetPlot(data, debug = False):\n",
    "    class_dist = data[targetColumnName].value_counts()\n",
    "\n",
    "    if debug == True:\n",
    "        print(class_dist)\n",
    "\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.title('Distribution of TARGET variable')\n",
    "    plt.barh(class_dist.index, class_dist.values)\n",
    "    plt.yticks([0, 1])\n",
    "\n",
    "    for i, value in enumerate(class_dist.values):\n",
    "        plt.text(value-2000, i, str(value), fontsize=12, color='white',\n",
    "                 horizontalalignment='right', verticalalignment='center')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showHeatmap(data):\n",
    "    corrmat = data.corr()\n",
    "    top_corr_features = corrmat.index\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #plot heat map\n",
    "    g=sns.heatmap(data[top_corr_features].corr(),cmap=\"RdYlGn\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Allocates data frames for each data type of argument data frame\n",
    "# @TODO: implement data frame of integer types not being labeled as categorical\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data:   dataframe to be split into respective types\n",
    "# @param debug: flag for displaying debugger output of writing columns into respective files\n",
    "#\n",
    "# Returns\n",
    "# ---------\n",
    "# strTypes           columns of string type\n",
    "# continuousTypes    columns of continuous variables\n",
    "# categorical        columns of categorical types\n",
    "#\n",
    "def allocateTypes(data, debug = False):\n",
    "    strTypes = data.select_dtypes(include='object')\n",
    "    continuousTypes = data.select_dtypes(include = ['float64', 'int64'])\n",
    "    if debug == True:\n",
    "        fd = open(stringVariablesFile, \"w+\")\n",
    "        fd.write(\"String-type variables:\\n\")\n",
    "        fd.write(lineString)\n",
    "        for col in strTypes.columns: \n",
    "            fd.write(col + \"\\n\")\n",
    "        fd.close()\n",
    "        fd = open(continuousVariablesFile, \"w+\")\n",
    "        fd.write(\"Continuous-type variables:\\n\")\n",
    "        fd.write(lineString)\n",
    "        for col in continuousTypes.columns: \n",
    "            fd.write(col + \"\\n\")\n",
    "        fd.close()\n",
    "        print(\"allocateTypes...success\")\n",
    "    return strTypes, continuousTypes\n",
    "\n",
    "\n",
    "# Workaround to insert string into file without overwriting contents\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param originalfile: original file name\n",
    "# @param string:       string to be written to file\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def insert(originalfile,string):\n",
    "    with open(originalfile,'r') as f:\n",
    "        with open('newfile.txt','w') as f2: \n",
    "            f2.write(string)\n",
    "            f2.write(f.read())\n",
    "    os.rename('newfile.txt',originalfile)\n",
    "\n",
    "\n",
    "# @TODO: figure out a try except for the format of the numpy array printed out\n",
    "# Prints a data frame\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to be printed\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def printDataFrame(data):\n",
    "    numpy_array = data.to_numpy()\n",
    "    numpy_array = [i for i in numpy_array if str(i) != 'nan']\n",
    "    \n",
    "    try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%d\")\n",
    "    except:\n",
    "        try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%s\")\n",
    "        except:\n",
    "            try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%f\")\n",
    "            except: print(\"error in types\")\n",
    "    \n",
    "    columnNames = \"\"\n",
    "    for i in data.columns:\n",
    "        columnNames = columnNames + i + \" \"\n",
    "    columnNames = columnNames + \"\\n\"\n",
    "    insert(dataFrameFileName, columnNames)\n",
    "\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Helper Functions Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab83f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method:\n",
    "#-------------\n",
    "# Reads in the data files, plots certain values and creates useful analytical plots and does\n",
    "# some light data cleaning\n",
    "#\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug:             flag for displaying debugger output\n",
    "# @param dropMissingValues: true to drop rows with empty values, false to set null values to mean\n",
    "# @param: savePlots:        true to plot various initial data points\n",
    "# @param outlierThreshold:  z-value with which to threshold outliers\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def main(debug = True, dropMissingValues = False, savePlots = False, outlierThreshold = 3):\n",
    "\n",
    "    # Create output directories for files and plots to be saved to\n",
    "    createOutputDirectories(debug)\n",
    "\n",
    "    # Read the data, assigning independant and dependant variables: x and y respectively\n",
    "    data, x, y = readData(datasetName, targetColumnName, debug)\n",
    "    \n",
    "    data = data.dropna(axis=0)\n",
    "    #df = df.dropna()\n",
    "\n",
    "    \n",
    "    # Shows distribution of independant variable, and shows heatmap, if desired\n",
    "    if savePlots == True:\n",
    "        showHeatmap(data)\n",
    "        showTargetPlot(data, debug)\n",
    "\n",
    "    # Drop missing values or fill in empty values with mean\n",
    "    if dropMissingValues == True: \n",
    "        data = dropMissingValues(data, debug)\n",
    "    else:\n",
    "        data = setMeanValues(data, debug)\n",
    "\n",
    "    # Show data distribution and allow for manual analysis of outliers\n",
    "    writeDistribution(data, debug)\n",
    "    \n",
    "    # Remove outliers past threshold of 3\n",
    "    #data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "\n",
    "    # Get sub-data frames that contain variables from each respective data type\n",
    "    data_strings, data_continuous, data_categorical = allocateTypes(data, debug)\n",
    "\n",
    "    # Feature engineering for a credit to income ratio\n",
    "    #data_continuous.insert(0, 'loan_ratio', data_continuous['AMT_CREDIT'] /data_continuous['AMT_INCOME_TOTAL'] / 100)\n",
    "    #plot_column(data_continuous, 'loan_ratio', ['box'])\n",
    "\n",
    "    # Show plots from data for outlier analysis\n",
    "    # [] denotes all variables to look at\n",
    "    if savePlots == True: \n",
    "        showPlots(data, [], debug)\n",
    "        for i in data_strings.columns:\n",
    "            plot_column(data_strings, i, ['bar'])\n",
    "        for i in data_continuous.columns:\n",
    "            plot_column(data_continuous, i, ['box'])\n",
    "        for i in data_categorical.columns:\n",
    "            plot_column(data_categorical, i, ['bar'])\n",
    "            \n",
    "    # show plots for chosen variables\n",
    "    topTenDf = data[chosenTopTenVariables]\n",
    "    # 10 plus TARGET\n",
    "    assert(len(topTenDf.columns) == 11)\n",
    "    #printDataFrame(topTenDf)\n",
    "    topTenStrings, topTenContinuous, topTenCategorical = allocateTypes(topTenDf, debug)\n",
    "    if savePlots == True:\n",
    "        for i in topTenStrings.columns:\n",
    "            plot_column(topTenStrings, i, ['bar'], dirName = 'images/topTenPlots/')\n",
    "        for i in topTenContinuous.columns:\n",
    "            plot_column(topTenContinuous, i, ['box'], dirName = 'images/topTenPlots/')\n",
    "        for i in topTenCategorical.columns:\n",
    "            plot_column(topTenCategorical, i, ['bar'], dirName = 'images/topTenPlots/')\n",
    "        \n",
    "    # One hot encoding for categorical variables\n",
    "    topTenStrings = pd.get_dummies(topTenStrings)\n",
    "    \n",
    "    # Target column for labels in value prediction\n",
    "    labels = np.array(data[targetColumnName])\n",
    "    \n",
    "    # Remove target column from features\n",
    "    topTenStrings = topTenStrings.drop(targetColumnName, axis = 1)\n",
    "    topTenContinuous = topTenContinuous.drop(targetColumnName, axis = 1)\n",
    "    topTenCategorical = topTenCategorical.drop(targetColumnName, axis = 1)\n",
    "    \n",
    "    # Save columnNames\n",
    "    stringsColumns = list(topTenStrings.columns)\n",
    "    continouousColumns = list(topTenContinuous.columns)\n",
    "    categoricalColumns = list(topTenCategorical.columns)\n",
    "    \n",
    "    # Concatenate data frames\n",
    "    features = pd.concat([topTenStrings, topTenContinuous, topTenCategorical], axis=1)\n",
    "    \n",
    "    #features = dropMissingValues(features, debug = debug)\n",
    "    features.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    #printDataFrame(topTenStrings)\n",
    "    #printDataFrame(topTenContinuous)\n",
    "    \n",
    "    feature_list = list(features.columns)\n",
    "    print(feature_list)\n",
    "    \n",
    "    #Convert to numpy array\n",
    "    strings = np.array(topTenStrings)\n",
    "    continuous = np.array(topTenContinuous)\n",
    "    categorical = np.array(topTenCategorical)\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    #@TODO: may not actually have to do anything to split into test and training sets...\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "    print('Training Features Shape:', train_features.shape)\n",
    "    print('Training Labels Shape:', train_labels.shape)\n",
    "    print('Testing Features Shape:', test_features.shape)\n",
    "    \n",
    "    #    >>> iris = load_iris()\n",
    "    #>>> X, y = iris.data, iris.target\n",
    "    #>>> clf = tree.DecisionTreeClassifier()\n",
    "    #>>> clf = clf.fit(X, y)\n",
    "    iris = load_iris()\n",
    "    train_features, train_labels = iris.data, iris.target\n",
    "\n",
    "    #X = [[0, 0], [1, 1]]\n",
    "    #Y = [0, 1]\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    #clf = clf.fit(topTenStrings, labels)\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    print(\"Finished clf\")\n",
    "    #tree.plot_tree(clf)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))  # set plot size (denoted in inches)\n",
    "    tree.plot_tree(clf, fontsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "    # The score method returns the accuracy of the model\n",
    "    #score = clf.score(test_features, test_labels)\n",
    "    #print(\"Printing clf score: \")\n",
    "    #print(score)\n",
    "    \n",
    "    # Predict for 1 observation\n",
    "    #clf.predict(X_test.iloc[0].values.reshape(1, -1))\n",
    "    # Predict for multiple observations\n",
    "    \n",
    "    #print(\"Classification Tree Predictions: \")\n",
    "    #print(clf.predict(test_features))\n",
    "    \n",
    "    #dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "    #dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "    #                  feature_names=feature_list,  \n",
    "    #                  class_names=iris.target_names,  \n",
    "    #                  filled=True, rounded=True,  \n",
    "    #                  special_characters=True)  \n",
    "    #graph = graphviz.Source(dot_data) \n",
    "    #graph.render(\"iris\") \n",
    "    #graph \n",
    "    \n",
    "    print(\"Finished graphing clf classifier\")\n",
    "    \n",
    "    clf = tree.DecisionTreeRegressor()\n",
    "    #clf = clf.fit(train_features, train_labels)\n",
    "    #plt.figure(figsize=(12,12))  # set plot size (denoted in inches)\n",
    "    #tree.plot_tree(clf, fontsize=10)\n",
    "    #plt.show()\n",
    "    \n",
    "    print(\"Finished graphing clf regressor\")\n",
    "    \n",
    "    # Instantiate model with 1000 decision trees\n",
    "    #rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    #rf.fit(train_features, train_labels);\n",
    "\n",
    "    # Set up random tree forest\n",
    "    # @TODO: make sure you figure out grouping first. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #split dataset in features and target variable\n",
    "    X = data[chosenTopTenVariables] # Features\n",
    "    y = data['TARGET'] # Target variable\n",
    "    \n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "    if debug == True:\n",
    "        debugFd.write(\"Main Method Cell Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f158af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmeans = {}\\nstds= {}\\nfor col in data.columns:\\n    if not isinstance(data[col][0], str):\\n        means[col] = data[col].mean()\\n        stds[col] = data[col].std()\\nprint(means)\\nprint(stds)\\nprint()\\n\\nprint(\"Data shape before removing outliers: \")\\nprint(data.shape)\\nfor i, row in enumerate(data.iterrows()):\\n    for key, item in means.items():\\n        print(key)\\n        print(data[key][i])\\n        #if np.abs(row[key] - means[key]) <= outlierThreshold*stds[key]:\\n        #    data.drop[data.index[i]]\\nprint(\"Data shape after removing outliers: \")\\nprint(data.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    #if debug == True:\n",
    "    #    print(\"Before dropping outliers\")\n",
    "    #    print(data.describe())\n",
    "    #   print()\n",
    "    \"\"\"\n",
    "    means = {}\n",
    "    stds= {}\n",
    "    for col in data.columns:\n",
    "        if not isinstance(data[col][0], str):\n",
    "            means[col] = data[col].mean()\n",
    "            stds[col] = data[col].std()\n",
    "    print(means)\n",
    "    print(stds)\n",
    "    print()\n",
    "    \n",
    "    print(\"Data shape before removing outliers: \")\n",
    "    print(data.shape)\n",
    "    for i, row in enumerate(data.iterrows()):\n",
    "        for key, item in means.items():\n",
    "            print(key)\n",
    "            print(data[key][i])\n",
    "            #if np.abs(row[key] - means[key]) <= outlierThreshold*stds[key]:\n",
    "            #    data.drop[data.index[i]]\n",
    "    print(\"Data shape after removing outliers: \")\n",
    "    print(data.shape)\n",
    "    \"\"\"    \n",
    "\n",
    "    #data[np.abs(data-data.mean()) <= (outlierThreshold*data.std())]\n",
    "    #if debug == True: \n",
    "    #    print(\"After dropping outliers\")\n",
    "    #    print(data.describe())\n",
    "    #    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f56dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method:\n",
    "#-------------\n",
    "# Reads in the data files, plots certain values and creates useful analytical plots and does\n",
    "# some light data cleaning\n",
    "#\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug:             flag for displaying debugger output\n",
    "# @param dropMissingValues: true to drop rows with empty values, false to set null values to mean\n",
    "# @param: savePlots:        true to plot various initial data points\n",
    "# @param outlierThreshold:  z-value with which to threshold outliers\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def pain(debug = True, dropMissingValues = False, savePlots = False, outlierThreshold = 3):\n",
    "\n",
    "    # Create output directories for files and plots to be saved to\n",
    "    createOutputDirectories(debug)\n",
    "\n",
    "    # Read the data, assigning independant and dependant variables: x and y respectively\n",
    "    data, x, y = readData(datasetName, targetColumnName, debug)\n",
    "    testData = pd.read_csv(testFileName)\n",
    "    # Assign data to only our top ten variables to save runtime and data cleaning\n",
    "    #data = data[chosenTopTenVariables]\n",
    "    data = data[forestTopTenVariables]\n",
    "    #assert(len(data.columns) == 10)\n",
    "    \n",
    "    # Drop bad values from the variables we care about\n",
    "    data = data.dropna(axis=0)\n",
    "    for col in data.columns:\n",
    "        assert(data[col].isnull().sum() == 0)\n",
    "    if debug == True:\n",
    "        print(\"Null data values properly dropped\")\n",
    "\n",
    "    # Allocate feature and label data frames\n",
    "    labels = pd.DataFrame()\n",
    "    labels[targetColumnName] = data[targetColumnName]\n",
    "    features = data.drop(targetColumnName, axis = 1)\n",
    "\n",
    "    # Normalize days birth to something reasonable\n",
    "    #yearsBorn = round(abs(features['DAYS_BIRTH'] / (365)))\n",
    "    #features['DAYS_BIRTH'] = round(abs(features['DAYS_BIRTH'] / (365)))\n",
    "\n",
    "    # Remove outliers past threshold of 3\n",
    "    #data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "\n",
    "    # Get sub-data frames that contain variables from each respective data type - we don't want target\n",
    "    dataStrings, dataContinuous = allocateTypes(features, debug)\n",
    "    \n",
    "    # One hot encoding for categorical variables\n",
    "    # We want to avoid multi-colinearity here, so drop the first categorical variable\n",
    "    if len(dataStrings.columns) > 0:\n",
    "        dataStrings = pd.get_dummies(dataStrings)\n",
    "    \n",
    "    # Re-merge data types now\n",
    "    features = dataContinuous.join(dataStrings)\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.7, random_state=1)\n",
    "    \n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    # Try to load the model from disk, else retrain (very time intensive)\n",
    "    #try:\n",
    "    #    clf = pickle.load(open('decision_tree_classifier.sav', 'rb'))\n",
    "    #    print(\"CLF loaded\")\n",
    "    #except Exception:\n",
    "        # Train Decision Tree Classifier\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(\"CLF fitted\")\n",
    "        \n",
    "    # save the model to disk\n",
    "    pickle.dump(clf, open('decision_tree_classifier_no_prune.sav', 'wb'))\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy of single decision tree:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Visualize tree\n",
    "    #dot_data = StringIO()\n",
    "    #export_graphviz(clf, out_file=dot_data,  \n",
    "    #            filled=True, rounded=True,\n",
    "    #            special_characters=True,feature_names = list(features.columns), class_names=['0','1'])\n",
    "    #graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    #graph.write_png('CLF.png')\n",
    "    #Image(graph.create_png())\n",
    "    #print(\"Finished writing tree\")\n",
    "    \n",
    "    # Plot Feature Importance\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features.columns[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.savefig(\"featureImportances_single_tree.png\")\n",
    "    print(\"Finished plotting tree\")\n",
    "    \n",
    "\n",
    "    # Create random tree forest\n",
    "    model = RandomForestClassifier(n_estimators=1000, random_state=1)\n",
    "\n",
    "    #try:\n",
    "    #    model = pickle.load(open('decision_tree_forest_2.sav', 'rb'))\n",
    "    #except Exception:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Random forest accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #tree_small = model.estimators_[0]\n",
    "    #export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = list(features.columns), rounded = True, precision = 1)\n",
    "    #(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "    #graph.write_png('small_tree.png')\n",
    "    pickle.dump(model, open('decision_tree_forest_bad.sav', 'wb'))\n",
    "    \n",
    "    for name, importance in zip(list(features.columns), model.feature_importances_):\n",
    "        print(name, \" = \", importance)\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    #plt.figure(figsize=(30,30))\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features.columns[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.savefig(\"featureImportances.png\")\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    #rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    #rf.fit(train_features, train_labels);\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    #predictions = rf.predict(test_features)\n",
    "    # Calculate the absolute errors\n",
    "    #errors = abs(predictions - test_labels)\n",
    "    # Print out the mean absolute error (mae)\n",
    "    #print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    \n",
    "    if debug == True:\n",
    "        debugFd.write(\"Main Method Cell Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3b901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createOutputDirectories...success\n",
      "readData...completed\n",
      "Null data values properly dropped\n",
      "allocateTypes...success\n",
      "CLF fitted\n",
      "Accuracy of single decision tree: 0.8834410740924913\n",
      "Finished plotting tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_200420/3740447611.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy:  0.9351566384883143\n",
      "EXT_SOURCE_3  =  0.12537681272836296\n",
      "EXT_SOURCE_2  =  0.11896016445748715\n",
      "EXT_SOURCE_1  =  0.12726113257380547\n",
      "AMT_ANNUITY  =  0.09224629261939406\n",
      "DAYS_EMPLOYED  =  0.09702393828057675\n",
      "AMT_CREDIT  =  0.07738800162166574\n",
      "DAYS_ID_PUBLISH  =  0.10013896798588688\n",
      "DAYS_REGISTRATION  =  0.10442120445541163\n",
      "LIVINGAREA_MODE  =  0.09710289508719265\n",
      "AMT_GOODS_PRICE  =  0.060080590190216804\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pain(debug=debug, dropMissingValues=dropMissingValues, savePlots = savePlots, outlierThreshold = 3)\n",
    "    if debug == True:\n",
    "        debugFd.write(\"Module Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")\n",
    "        debugFd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e8776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc233c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
