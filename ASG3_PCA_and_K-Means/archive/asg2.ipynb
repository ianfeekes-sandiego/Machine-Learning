{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "209535cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "debug = True                        # Displays additional logging output\n",
    "savePlots = False                   # Saves plot image files\n",
    "targetColumnName = \"TARGET\"         # Name for column denoting dependant variable\n",
    "outlierThreshold = 3                # Number of standard deviations from which data will be classified as an outlier\n",
    "dropMissingValues = True #Needs to be true for randomTreeRegressor\n",
    "\n",
    "# Various file names for debugging and analysis\n",
    "stringVariablesFile =           './outputFiles/stringVariables.txt'\n",
    "continuousVariablesFile =       './outputFiles/continuousVariables.txt'\n",
    "categoricalVariablesFile =      './outputFiles/categoricalVariables.txt'\n",
    "datasetName =                   './dataset/application_train.csv'\n",
    "initialDataFileName =           './outputFiles/initialData.txt'\n",
    "missingValFileName =            './outputFiles/missingValueSummary.txt'\n",
    "noMissingValuesFileName =       './outputFiles/noMissingValueSummary.txt'\n",
    "initialDistributionFileName =   './outputFiles/initialDistribution.txt'\n",
    "dataFrameFileName =             './outputFiles/dataFrameDebug.txt'\n",
    "generalDebugFileName =          './debug.txt'\n",
    "testFileName =                  './dataset/application_test.csv'\n",
    "\n",
    "# Chosen top 10 variables from ASG1\n",
    "# @TODO: figure out if we want to do a mixture of ext source variables\n",
    "# @todo: figure out if we want to remove target from these columns\n",
    "chosenTopTenVariables = ['TARGET', 'NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'CODE_GENDER', 'EXT_SOURCE_1',\n",
    "                         'DAYS_BIRTH', 'CNT_CHILDREN', 'AMT_CREDIT', 'NAME_INCOME_TYPE',\n",
    "                         'NAME_EDUCATION_TYPE']\n",
    "\n",
    "forestTopTenVariables = ['EXT_SOURCE_3',\n",
    "                         'TARGET',\n",
    "'EXT_SOURCE_2',\n",
    "'EXT_SOURCE_1',\n",
    "'AMT_ANNUITY',\n",
    "'DAYS_EMPLOYED',\n",
    "'AMT_CREDIT',\n",
    "'DAYS_ID_PUBLISH',\n",
    "'DAYS_REGISTRATION',\n",
    "'LIVINGAREA_MODE',\n",
    "'AMT_GOODS_PRICE',\n",
    "]\n",
    "#, 'ORGANIZATION_TYPE'*/]\n",
    "\n",
    "lineString = \"---------------------------------------------------------------------------------------------------------\"\n",
    "\n",
    "debugFd = open(generalDebugFileName, \"w+\")\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Global Variables Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e13c9f7f-9248-447d-a522-de5f3b59344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Imports Cell Completed...\n",
      "---------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Library Imports\n",
    "from nis import cat\n",
    "from re import X\n",
    "import pandas as pd                 # Used for data frame\n",
    "import plotly                       # Saves html plots\n",
    "import plotly.express as px         # Used for displaying plots\n",
    "import os                           # Allows file manipulation and console debugging for offline jupyter\n",
    "import numpy as np\n",
    "from scipy import stats             # Used for outliers\n",
    "import matplotlib.pyplot as plt     # Used for pyplot heatmap plotting\n",
    "import seaborn as sns               # Used for showing heatmap\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix\n",
    "    # Import the model we are using\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#@TODO: Figure out if we want to delete this or not and use the sklearn tree\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "import graphviz # Data Tree Visualization\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "import pickle                                   # Saving Models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import graphviz # Data Tree Visualization\n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO  \n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "import pydot\n",
    "\n",
    "import phik\n",
    "\n",
    "from phik import resources\n",
    "from phik.binning import bin_data\n",
    "from phik.report import plot_correlation_matrix\n",
    "\n",
    "if debug == True:\n",
    "    print(\"Library Imports Cell Completed...\")\n",
    "    print(lineString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16fd574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Module Imports\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Module Imports Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962cad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software configurations\n",
    "pd.options.display.max_rows = 4000  # Allows better debugging analysis\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Software Configuration Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed7c79d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# If the debugging flag is on, creates directories to store output data\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def createOutputDirectories(debug = False):\n",
    "    if debug == False:\n",
    "        return\n",
    "    if not os.path.exists(\"images\"):\n",
    "        os.mkdir(\"images\")\n",
    "    if not os.path.exists(\"images/initialPlots\"):\n",
    "        os.mkdir(\"images/initialPlots\")\n",
    "    if not os.path.exists(\"images/topTenPlots\"):\n",
    "        os.mkdir(\"images/topTenPlots\")\n",
    "    if not os.path.exists(\"outputFiles\"):\n",
    "        os.mkdir(\"outputFiles\")\n",
    "    print(\"createOutputDirectories...success\")\n",
    "\n",
    "\n",
    "# Reads csv file into data frame and sets independant and dependant variables\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param fileName: string for full relative file path of csv file\n",
    "# @param dependantVarColumnName: csv file column matching name of column for dependant variable\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# data: dataframe object of csv file reading\n",
    "# independantVars: independant variables (all data that isn't targetColumnName)\n",
    "# dependantVar: dependant variable\n",
    "#\n",
    "def readData(fileName, dependantVarColumnName = targetColumnName, debug = False):\n",
    "    independantVars = []\n",
    "    dependantVar = []\n",
    "    data = pd.read_csv(fileName)\n",
    "    index = None\n",
    "    for i ,col in enumerate(data.columns):\n",
    "        if col == dependantVarColumnName:\n",
    "            index = i\n",
    "    if index != None: \n",
    "        dependantVar = data.iloc[:, index]\n",
    "        independantVars = data.iloc[:]\n",
    "        independantVars.pop(dependantVarColumnName)\n",
    "    if debug:\n",
    "        fd = open(initialDataFileName, \"w+\")\n",
    "        fd.write(\"This file contains the initial data frame without cleaning:\\n\")\n",
    "        fd.write(str(data))\n",
    "        fd.close()\n",
    "        print(\"readData...completed\")\n",
    "    return data, independantVars, dependantVar\n",
    "\n",
    "\n",
    "# Drops rows from dataset which are missing. Prints missing value data for debugging\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to have missing values dropped and returned\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# data: dataframe object with missing values dropped\n",
    "#\n",
    "def dropMissingValues(data, debug = False):\n",
    "    # Drop missing values\n",
    "    ret = data.dropna(axis=0)\n",
    "    # Show number of missing values per independant variable\n",
    "    if debug:\n",
    "        fd = open(missingValFileName, \"w+\")\n",
    "        fd.write(\"This data shows the independant variables which contained missing values and the count of each:\\n\")\n",
    "        fd.write(str(data.isnull().sum()))\n",
    "        fd.close()\n",
    "        fd = open(noMissingValuesFileName, \"w+\")\n",
    "        fd.write(\"This data shows the independant variables which are used for analysis with no mising values:\\n\")\n",
    "        fd.write(str(ret.isnull().sum()))\n",
    "        fd.close()\n",
    "        print(\"dropMissingValues...completed\")\n",
    "    return ret\n",
    "\n",
    "\n",
    "def setMeanValues(data, debug = False):\n",
    "    return data\n",
    "\n",
    "# Writes distribution of data frame to text file\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to have distribution written to text file\n",
    "# @param debug: flag for displaying debugger output\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def writeDistribution(data, debug = False):\n",
    "    if debug == False:\n",
    "        return\n",
    "    numpy_array = data.to_numpy()\n",
    "    fd = open(initialDistributionFileName, \"w+\")\n",
    "    fd.write(str(numpy_array))\n",
    "    fd.close()\n",
    "    print(\"writeDistribution...success\")\n",
    "\n",
    "\n",
    "def doBar(data, column_name, figsize = (18,6), \n",
    "          percentage_display = True,\n",
    "          plot_defaulter = True, rotation = 0, \n",
    "          horizontal_adjust = 0, \n",
    "          fontsize_percent = 'xx-small',\n",
    "          dirName = 'images/initialPlots/'):\n",
    "\n",
    "    \n",
    "    print(f\"Total Number of unique categories of {column_name} = {len(data[column_name].unique())}\")\n",
    "    \n",
    "    plt.figure(figsize = figsize, tight_layout = False)\n",
    "    sns.set(style = 'whitegrid', font_scale = 1.2)\n",
    "    \n",
    "    #plotting overall distribution of category\n",
    "    plt.subplot(1,2,1)\n",
    "    data_to_plot = data[column_name].value_counts().sort_values(ascending = False)\n",
    "    ax = sns.barplot(x = data_to_plot.index, y = data_to_plot, palette = 'Set1')\n",
    "    \n",
    "    if percentage_display:\n",
    "        total_datapoints = len(data[column_name].dropna())\n",
    "        for p in ax.patches:\n",
    "            ax.text(p.get_x() + horizontal_adjust, p.get_height() + 0.005 * total_datapoints, '{:1.02f}%'.format(p.get_height() * 100 / total_datapoints), fontsize = fontsize_percent)\n",
    "        \n",
    "    plt.xlabel(column_name, labelpad = 10)\n",
    "    plt.title(f'Distribution of {column_name}', pad = 20)\n",
    "    plt.xticks(rotation = rotation)\n",
    "    plt.ylabel('Counts')\n",
    "    \n",
    "    #plotting distribution of category for Defaulters\n",
    "    if plot_defaulter:\n",
    "        percentage_defaulter_per_category = (data[column_name][data.TARGET == 1].value_counts() * 100 / data[column_name].value_counts()).dropna().sort_values(ascending = False)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        sns.barplot(x = percentage_defaulter_per_category.index, y = percentage_defaulter_per_category, palette = 'Set2')\n",
    "        plt.ylabel('Percentage of Defaulter per category')\n",
    "        plt.xlabel(column_name, labelpad = 10)\n",
    "        plt.xticks(rotation = rotation)\n",
    "        plt.title(f'Percentage of Defaulters for each category of {column_name}', pad = 20)\n",
    "\n",
    "    fileName = dirName + column_name + '.png'\n",
    "    plt.savefig(fileName)\n",
    "\n",
    "\n",
    "# Plots a column name of the dataframe and saves each plot into a file\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data:       dataframe to have distribution written to text file\n",
    "# @param plots:      types of plots for each column to show e.g. \"box\"\n",
    "# @param: figsize:   size of figure for matplotlib to plot\n",
    "# @param: log_scale: flag to log the scale of the plot\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def plot_column(data,\n",
    "                column_name,\n",
    "                plots = [],\n",
    "                figsize = (20,8),\n",
    "                log_scale = False,\n",
    "                dirName = 'images/initialPlots/'):\n",
    "\n",
    "    if 'bar' in plots:\n",
    "        doBar(data, column_name, figsize, dirName = dirName)\n",
    "        return\n",
    "    data_to_plot = data.copy()\n",
    "    plt.figure(figsize = figsize)\n",
    "    sns.set_style('whitegrid')\n",
    "    \n",
    "    for i, ele in enumerate(plots):\n",
    "        plt.subplot(1, len(plots), i + 1)\n",
    "        plt.subplots_adjust(wspace=0.25)\n",
    "        if ele == 'CDF':\n",
    "            #making the percentile DataFrame for both positive and negative Class Labels\n",
    "            percentile_values_0 = data_to_plot[data_to_plot.TARGET == 0][[column_name]].dropna().sort_values(by = column_name)\n",
    "            percentile_values_0['Percentile'] = [ele / (len(percentile_values_0)-1) for ele in range(len(percentile_values_0))]\n",
    "            \n",
    "            percentile_values_1 = data_to_plot[data_to_plot.TARGET == 1][[column_name]].dropna().sort_values(by = column_name)\n",
    "            percentile_values_1['Percentile'] = [ele / (len(percentile_values_1)-1) for ele in range(len(percentile_values_1))]\n",
    "            \n",
    "            plt.plot(percentile_values_0[column_name], percentile_values_0['Percentile'], color = 'red', label = 'Non-Defaulters')\n",
    "            plt.plot(percentile_values_1[column_name], percentile_values_1['Percentile'], color = 'black', label = 'Defaulters')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Probability')\n",
    "            plt.title('CDF of {}'.format(column_name))\n",
    "            plt.legend(fontsize = 'medium')\n",
    "            if log_scale:\n",
    "                plt.xscale('log')\n",
    "                plt.xlabel(column_name + ' - (log-scale)')\n",
    "        elif ele == 'distplot':\n",
    "            sns.distplot(data_to_plot[column_name][data['TARGET'] == 0].dropna(),\n",
    "                         label='Non-Defaulters', hist = False, color='red')\n",
    "            sns.distplot(data_to_plot[column_name][data['TARGET'] == 1].dropna(),\n",
    "                         label='Defaulters', hist = False, color='black')\n",
    "            plt.xlabel(column_name)\n",
    "            plt.ylabel('Probability Density')\n",
    "            plt.legend(fontsize='medium')\n",
    "            plt.title(\"Dist-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.xscale('log')\n",
    "                plt.xlabel(f'{column_name} (log scale)')\n",
    "        elif ele == 'violin':  \n",
    "            sns.violinplot(x='TARGET', y=column_name, data=data_to_plot)\n",
    "            plt.title(\"Violin-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.yscale('log')\n",
    "                plt.ylabel(f'{column_name} (log Scale)')\n",
    "        elif ele == 'box':  \n",
    "            sns.boxplot(x='TARGET', y=column_name, data=data_to_plot)\n",
    "            plt.title(\"Box-Plot of {}\".format(column_name))\n",
    "            if log_scale:\n",
    "                plt.yscale('log')\n",
    "                plt.ylabel(f'{column_name} (log Scale)')\n",
    "\n",
    "    fileName = dirName + column_name + '.png'\n",
    "    plt.savefig(fileName)\n",
    "\n",
    "\n",
    "def showTargetPlot(data, debug = False):\n",
    "    class_dist = data[targetColumnName].value_counts()\n",
    "\n",
    "    if debug == True:\n",
    "        print(class_dist)\n",
    "\n",
    "    plt.figure(figsize=(12,3))\n",
    "    plt.title('Distribution of TARGET variable')\n",
    "    plt.barh(class_dist.index, class_dist.values)\n",
    "    plt.yticks([0, 1])\n",
    "\n",
    "    for i, value in enumerate(class_dist.values):\n",
    "        plt.text(value-2000, i, str(value), fontsize=12, color='white',\n",
    "                 horizontalalignment='right', verticalalignment='center')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def showHeatmap(data):\n",
    "    corrmat = data.corr()\n",
    "    top_corr_features = corrmat.index\n",
    "    plt.figure(figsize=(20,20))\n",
    "    #plot heat map\n",
    "    g=sns.heatmap(data[top_corr_features].corr(),cmap=\"RdYlGn\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Allocates data frames for each data type of argument data frame\n",
    "# @TODO: implement data frame of integer types not being labeled as categorical\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data:   dataframe to be split into respective types\n",
    "# @param debug: flag for displaying debugger output of writing columns into respective files\n",
    "#\n",
    "# Returns\n",
    "# ---------\n",
    "# strTypes           columns of string type\n",
    "# continuousTypes    columns of continuous variables\n",
    "# categorical        columns of categorical types\n",
    "#\n",
    "def allocateTypes(data, debug = False):\n",
    "    strTypes = data.select_dtypes(include='object')\n",
    "    continuousTypes = data.select_dtypes(include = ['float64', 'int64'])\n",
    "    if debug == True:\n",
    "        fd = open(stringVariablesFile, \"w+\")\n",
    "        fd.write(\"String-type variables:\\n\")\n",
    "        fd.write(lineString)\n",
    "        for col in strTypes.columns: \n",
    "            fd.write(col + \"\\n\")\n",
    "        fd.close()\n",
    "        fd = open(continuousVariablesFile, \"w+\")\n",
    "        fd.write(\"Continuous-type variables:\\n\")\n",
    "        fd.write(lineString)\n",
    "        for col in continuousTypes.columns: \n",
    "            fd.write(col + \"\\n\")\n",
    "        fd.close()\n",
    "        print(\"allocateTypes...success\")\n",
    "    return strTypes, continuousTypes\n",
    "\n",
    "\n",
    "# Workaround to insert string into file without overwriting contents\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param originalfile: original file name\n",
    "# @param string:       string to be written to file\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def insert(originalfile,string):\n",
    "    with open(originalfile,'r') as f:\n",
    "        with open('newfile.txt','w') as f2: \n",
    "            f2.write(string)\n",
    "            f2.write(f.read())\n",
    "    os.rename('newfile.txt',originalfile)\n",
    "\n",
    "\n",
    "# @TODO: figure out a try except for the format of the numpy array printed out\n",
    "# Prints a data frame\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param data: dataframe to be printed\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def printDataFrame(data):\n",
    "    numpy_array = data.to_numpy()\n",
    "    numpy_array = [i for i in numpy_array if str(i) != 'nan']\n",
    "    \n",
    "    try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%d\")\n",
    "    except:\n",
    "        try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%s\")\n",
    "        except:\n",
    "            try: np.savetxt(dataFrameFileName, numpy_array, fmt = \"%f\")\n",
    "            except: print(\"error in types\")\n",
    "    \n",
    "    columnNames = \"\"\n",
    "    for i in data.columns:\n",
    "        columnNames = columnNames + i + \" \"\n",
    "    columnNames = columnNames + \"\\n\"\n",
    "    insert(dataFrameFileName, columnNames)\n",
    "\n",
    "\n",
    "if debug == True:\n",
    "    debugFd.write(\"Helper Functions Cell Completed...\\n\")\n",
    "    debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab83f36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method:\n",
    "#-------------\n",
    "# Reads in the data files, plots certain values and creates useful analytical plots and does\n",
    "# some light data cleaning\n",
    "#\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug:             flag for displaying debugger output\n",
    "# @param dropMissingValues: true to drop rows with empty values, false to set null values to mean\n",
    "# @param: savePlots:        true to plot various initial data points\n",
    "# @param outlierThreshold:  z-value with which to threshold outliers\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def main(debug = True, dropMissingValues = False, savePlots = False, outlierThreshold = 3):\n",
    "\n",
    "    # Create output directories for files and plots to be saved to\n",
    "    createOutputDirectories(debug)\n",
    "\n",
    "    # Read the data, assigning independant and dependant variables: x and y respectively\n",
    "    data, x, y = readData(datasetName, targetColumnName, debug)\n",
    "    \n",
    "    data = data.dropna(axis=0)\n",
    "    #df = df.dropna()\n",
    "\n",
    "    \n",
    "    # Shows distribution of independant variable, and shows heatmap, if desired\n",
    "    if savePlots == True:\n",
    "        showHeatmap(data)\n",
    "        showTargetPlot(data, debug)\n",
    "\n",
    "    # Drop missing values or fill in empty values with mean\n",
    "    if dropMissingValues == True: \n",
    "        data = dropMissingValues(data, debug)\n",
    "    else:\n",
    "        data = setMeanValues(data, debug)\n",
    "\n",
    "    # Show data distribution and allow for manual analysis of outliers\n",
    "    writeDistribution(data, debug)\n",
    "    \n",
    "    # Remove outliers past threshold of 3\n",
    "    #data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "\n",
    "    # Get sub-data frames that contain variables from each respective data type\n",
    "    data_strings, data_continuous, data_categorical = allocateTypes(data, debug)\n",
    "\n",
    "    # Feature engineering for a credit to income ratio\n",
    "    #data_continuous.insert(0, 'loan_ratio', data_continuous['AMT_CREDIT'] /data_continuous['AMT_INCOME_TOTAL'] / 100)\n",
    "    #plot_column(data_continuous, 'loan_ratio', ['box'])\n",
    "\n",
    "    # Show plots from data for outlier analysis\n",
    "    # [] denotes all variables to look at\n",
    "    if savePlots == True: \n",
    "        showPlots(data, [], debug)\n",
    "        for i in data_strings.columns:\n",
    "            plot_column(data_strings, i, ['bar'])\n",
    "        for i in data_continuous.columns:\n",
    "            plot_column(data_continuous, i, ['box'])\n",
    "        for i in data_categorical.columns:\n",
    "            plot_column(data_categorical, i, ['bar'])\n",
    "            \n",
    "    # show plots for chosen variables\n",
    "    topTenDf = data[chosenTopTenVariables]\n",
    "    # 10 plus TARGET\n",
    "    assert(len(topTenDf.columns) == 11)\n",
    "    #printDataFrame(topTenDf)\n",
    "    topTenStrings, topTenContinuous, topTenCategorical = allocateTypes(topTenDf, debug)\n",
    "    if savePlots == True:\n",
    "        for i in topTenStrings.columns:\n",
    "            plot_column(topTenStrings, i, ['bar'], dirName = 'images/topTenPlots/')\n",
    "        for i in topTenContinuous.columns:\n",
    "            plot_column(topTenContinuous, i, ['box'], dirName = 'images/topTenPlots/')\n",
    "        for i in topTenCategorical.columns:\n",
    "            plot_column(topTenCategorical, i, ['bar'], dirName = 'images/topTenPlots/')\n",
    "        \n",
    "    # One hot encoding for categorical variables\n",
    "    topTenStrings = pd.get_dummies(topTenStrings)\n",
    "    \n",
    "    # Target column for labels in value prediction\n",
    "    labels = np.array(data[targetColumnName])\n",
    "    \n",
    "    # Remove target column from features\n",
    "    topTenStrings = topTenStrings.drop(targetColumnName, axis = 1)\n",
    "    topTenContinuous = topTenContinuous.drop(targetColumnName, axis = 1)\n",
    "    topTenCategorical = topTenCategorical.drop(targetColumnName, axis = 1)\n",
    "    \n",
    "    # Save columnNames\n",
    "    stringsColumns = list(topTenStrings.columns)\n",
    "    continouousColumns = list(topTenContinuous.columns)\n",
    "    categoricalColumns = list(topTenCategorical.columns)\n",
    "    \n",
    "    # Concatenate data frames\n",
    "    features = pd.concat([topTenStrings, topTenContinuous, topTenCategorical], axis=1)\n",
    "    \n",
    "    #features = dropMissingValues(features, debug = debug)\n",
    "    features.dropna(axis=0, how='all', inplace=True)\n",
    "\n",
    "    #printDataFrame(topTenStrings)\n",
    "    #printDataFrame(topTenContinuous)\n",
    "    \n",
    "    feature_list = list(features.columns)\n",
    "    print(feature_list)\n",
    "    \n",
    "    #Convert to numpy array\n",
    "    strings = np.array(topTenStrings)\n",
    "    continuous = np.array(topTenContinuous)\n",
    "    categorical = np.array(topTenCategorical)\n",
    "\n",
    "    features = np.array(features)\n",
    "    \n",
    "    #@TODO: may not actually have to do anything to split into test and training sets...\n",
    "    # Split the data into training and testing sets\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)\n",
    "    \n",
    "    print('Training Features Shape:', train_features.shape)\n",
    "    print('Training Labels Shape:', train_labels.shape)\n",
    "    print('Testing Features Shape:', test_features.shape)\n",
    "    \n",
    "    #    >>> iris = load_iris()\n",
    "    #>>> X, y = iris.data, iris.target\n",
    "    #>>> clf = tree.DecisionTreeClassifier()\n",
    "    #>>> clf = clf.fit(X, y)\n",
    "    iris = load_iris()\n",
    "    train_features, train_labels = iris.data, iris.target\n",
    "\n",
    "    #X = [[0, 0], [1, 1]]\n",
    "    #Y = [0, 1]\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "    #clf = clf.fit(topTenStrings, labels)\n",
    "    clf = clf.fit(train_features, train_labels)\n",
    "    print(\"Finished clf\")\n",
    "    #tree.plot_tree(clf)\n",
    "    \n",
    "    plt.figure(figsize=(12,12))  # set plot size (denoted in inches)\n",
    "    tree.plot_tree(clf, fontsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "    # The score method returns the accuracy of the model\n",
    "    #score = clf.score(test_features, test_labels)\n",
    "    #print(\"Printing clf score: \")\n",
    "    #print(score)\n",
    "    \n",
    "    # Predict for 1 observation\n",
    "    #clf.predict(X_test.iloc[0].values.reshape(1, -1))\n",
    "    # Predict for multiple observations\n",
    "    \n",
    "    #print(\"Classification Tree Predictions: \")\n",
    "    #print(clf.predict(test_features))\n",
    "    \n",
    "    #dot_data = tree.export_graphviz(clf, out_file=None) \n",
    "    #dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "    #                  feature_names=feature_list,  \n",
    "    #                  class_names=iris.target_names,  \n",
    "    #                  filled=True, rounded=True,  \n",
    "    #                  special_characters=True)  \n",
    "    #graph = graphviz.Source(dot_data) \n",
    "    #graph.render(\"iris\") \n",
    "    #graph \n",
    "    \n",
    "    print(\"Finished graphing clf classifier\")\n",
    "    \n",
    "    clf = tree.DecisionTreeRegressor()\n",
    "    #clf = clf.fit(train_features, train_labels)\n",
    "    #plt.figure(figsize=(12,12))  # set plot size (denoted in inches)\n",
    "    #tree.plot_tree(clf, fontsize=10)\n",
    "    #plt.show()\n",
    "    \n",
    "    print(\"Finished graphing clf regressor\")\n",
    "    \n",
    "    # Instantiate model with 1000 decision trees\n",
    "    #rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    #rf.fit(train_features, train_labels);\n",
    "\n",
    "    # Set up random tree forest\n",
    "    # @TODO: make sure you figure out grouping first. \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #split dataset in features and target variable\n",
    "    X = data[chosenTopTenVariables] # Features\n",
    "    y = data['TARGET'] # Target variable\n",
    "    \n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1) # 70% training and 30% test\n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "    # Train Decision Tree Classifer\n",
    "    clf = clf.fit(X_train,y_train)\n",
    "\n",
    "    #Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "    \n",
    "    if debug == True:\n",
    "        debugFd.write(\"Main Method Cell Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f158af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmeans = {}\\nstds= {}\\nfor col in data.columns:\\n    if not isinstance(data[col][0], str):\\n        means[col] = data[col].mean()\\n        stds[col] = data[col].std()\\nprint(means)\\nprint(stds)\\nprint()\\n\\nprint(\"Data shape before removing outliers: \")\\nprint(data.shape)\\nfor i, row in enumerate(data.iterrows()):\\n    for key, item in means.items():\\n        print(key)\\n        print(data[key][i])\\n        #if np.abs(row[key] - means[key]) <= outlierThreshold*stds[key]:\\n        #    data.drop[data.index[i]]\\nprint(\"Data shape after removing outliers: \")\\nprint(data.shape)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    #if debug == True:\n",
    "    #    print(\"Before dropping outliers\")\n",
    "    #    print(data.describe())\n",
    "    #   print()\n",
    "    \"\"\"\n",
    "    means = {}\n",
    "    stds= {}\n",
    "    for col in data.columns:\n",
    "        if not isinstance(data[col][0], str):\n",
    "            means[col] = data[col].mean()\n",
    "            stds[col] = data[col].std()\n",
    "    print(means)\n",
    "    print(stds)\n",
    "    print()\n",
    "    \n",
    "    print(\"Data shape before removing outliers: \")\n",
    "    print(data.shape)\n",
    "    for i, row in enumerate(data.iterrows()):\n",
    "        for key, item in means.items():\n",
    "            print(key)\n",
    "            print(data[key][i])\n",
    "            #if np.abs(row[key] - means[key]) <= outlierThreshold*stds[key]:\n",
    "            #    data.drop[data.index[i]]\n",
    "    print(\"Data shape after removing outliers: \")\n",
    "    print(data.shape)\n",
    "    \"\"\"    \n",
    "\n",
    "    #data[np.abs(data-data.mean()) <= (outlierThreshold*data.std())]\n",
    "    #if debug == True: \n",
    "    #    print(\"After dropping outliers\")\n",
    "    #    print(data.describe())\n",
    "    #    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f56dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main Method:\n",
    "#-------------\n",
    "# Reads in the data files, plots certain values and creates useful analytical plots and does\n",
    "# some light data cleaning\n",
    "#\n",
    "#\n",
    "# Parameters:\n",
    "# -----------\n",
    "# @param debug:             flag for displaying debugger output\n",
    "# @param dropMissingValues: true to drop rows with empty values, false to set null values to mean\n",
    "# @param: savePlots:        true to plot various initial data points\n",
    "# @param outlierThreshold:  z-value with which to threshold outliers\n",
    "#\n",
    "# Returns:\n",
    "# ---------\n",
    "# None\n",
    "#\n",
    "def pain(debug = True, dropMissingValues = False, savePlots = False, outlierThreshold = 3):\n",
    "\n",
    "    # Create output directories for files and plots to be saved to\n",
    "    createOutputDirectories(debug)\n",
    "\n",
    "    # Read the data, assigning independant and dependant variables: x and y respectively\n",
    "    data, x, y = readData(datasetName, targetColumnName, debug)\n",
    "    testData = pd.read_csv(testFileName)\n",
    "    # Assign data to only our top ten variables to save runtime and data cleaning\n",
    "    #data = data[chosenTopTenVariables]\n",
    "    data = data[forestTopTenVariables]\n",
    "    #assert(len(data.columns) == 10)\n",
    "    \n",
    "    # Drop bad values from the variables we care about\n",
    "    data = data.dropna(axis=0)\n",
    "    for col in data.columns:\n",
    "        assert(data[col].isnull().sum() == 0)\n",
    "    if debug == True:\n",
    "        print(\"Null data values properly dropped\")\n",
    "\n",
    "    # Allocate feature and label data frames\n",
    "    labels = pd.DataFrame()\n",
    "    labels[targetColumnName] = data[targetColumnName]\n",
    "    features = data.drop(targetColumnName, axis = 1)\n",
    "\n",
    "    # Normalize days birth to something reasonable\n",
    "    #yearsBorn = round(abs(features['DAYS_BIRTH'] / (365)))\n",
    "    #features['DAYS_BIRTH'] = round(abs(features['DAYS_BIRTH'] / (365)))\n",
    "\n",
    "    # Remove outliers past threshold of 3\n",
    "    #data[(np.abs(stats.zscore(data)) < 3).all(axis=1)]\n",
    "\n",
    "    # Get sub-data frames that contain variables from each respective data type - we don't want target\n",
    "    dataStrings, dataContinuous = allocateTypes(features, debug)\n",
    "    \n",
    "    # One hot encoding for categorical variables\n",
    "    # We want to avoid multi-colinearity here, so drop the first categorical variable\n",
    "    if len(dataStrings.columns) > 0:\n",
    "        dataStrings = pd.get_dummies(dataStrings)\n",
    "    \n",
    "    # Re-merge data types now\n",
    "    features = dataContinuous.join(dataStrings)\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.7, random_state=1)\n",
    "    \n",
    "    \n",
    "    # Create Decision Tree classifer object\n",
    "    clf = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    # Try to load the model from disk, else retrain (very time intensive)\n",
    "    #try:\n",
    "    #    clf = pickle.load(open('decision_tree_classifier.sav', 'rb'))\n",
    "    #    print(\"CLF loaded\")\n",
    "    #except Exception:\n",
    "        # Train Decision Tree Classifier\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print(\"CLF fitted\")\n",
    "        \n",
    "    # save the model to disk\n",
    "    pickle.dump(clf, open('decision_tree_classifier_no_prune.sav', 'wb'))\n",
    "\n",
    "    # Predict the response for test dataset\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Model Accuracy, how often is the classifier correct?\n",
    "    print(\"Accuracy of single decision tree:\",metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    # Visualize tree\n",
    "    #dot_data = StringIO()\n",
    "    #export_graphviz(clf, out_file=dot_data,  \n",
    "    #            filled=True, rounded=True,\n",
    "    #            special_characters=True,feature_names = list(features.columns), class_names=['0','1'])\n",
    "    #graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    #graph.write_png('CLF.png')\n",
    "    #Image(graph.create_png())\n",
    "    #print(\"Finished writing tree\")\n",
    "    \n",
    "    # Plot Feature Importance\n",
    "    importances = clf.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features.columns[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.savefig(\"featureImportances_single_tree.png\")\n",
    "    print(\"Finished plotting tree\")\n",
    "    \n",
    "\n",
    "    # Create random tree forest\n",
    "    model = RandomForestClassifier(n_estimators=1000, random_state=1)\n",
    "\n",
    "    #try:\n",
    "    #    model = pickle.load(open('decision_tree_forest_2.sav', 'rb'))\n",
    "    #except Exception:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Random forest accuracy: \", metrics.accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    #tree_small = model.estimators_[0]\n",
    "    #export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = list(features.columns), rounded = True, precision = 1)\n",
    "    #(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "    #graph.write_png('small_tree.png')\n",
    "    pickle.dump(model, open('decision_tree_forest_bad.sav', 'wb'))\n",
    "    \n",
    "    for name, importance in zip(list(features.columns), model.feature_importances_):\n",
    "        print(name, \" = \", importance)\n",
    "    \n",
    "    importances = model.feature_importances_\n",
    "    indices = np.argsort(importances)\n",
    "    plt.title('Feature Importances')\n",
    "    #plt.figure(figsize=(30,30))\n",
    "    plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "    plt.yticks(range(len(indices)), [features.columns[i] for i in indices])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.savefig(\"featureImportances.png\")\n",
    "\n",
    "    # Instantiate model with 1000 decision trees\n",
    "    #rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "    # Train the model on training data\n",
    "    #rf.fit(train_features, train_labels);\n",
    "    \n",
    "    # Use the forest's predict method on the test data\n",
    "    #predictions = rf.predict(test_features)\n",
    "    # Calculate the absolute errors\n",
    "    #errors = abs(predictions - test_labels)\n",
    "    # Print out the mean absolute error (mae)\n",
    "    #print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "    \n",
    "    if debug == True:\n",
    "        debugFd.write(\"Main Method Cell Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e3b901c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createOutputDirectories...success\n",
      "readData...completed\n",
      "Null data values properly dropped\n",
      "allocateTypes...success\n",
      "CLF fitted\n",
      "Accuracy of single decision tree: 0.8821233217304824\n",
      "Finished plotting tree\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_201006/3225641436.py:112: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model.fit(X_train, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy:  0.9351815017404277\n",
      "EXT_SOURCE_3  =  0.12428167336044083\n",
      "EXT_SOURCE_2  =  0.12026174879729763\n",
      "EXT_SOURCE_1  =  0.12570107845853307\n",
      "AMT_ANNUITY  =  0.09223254096879527\n",
      "DAYS_EMPLOYED  =  0.09517474112262113\n",
      "AMT_CREDIT  =  0.0754661277505165\n",
      "DAYS_ID_PUBLISH  =  0.10045670547639618\n",
      "DAYS_REGISTRATION  =  0.10606610302166326\n",
      "LIVINGAREA_MODE  =  0.09915402337609518\n",
      "AMT_GOODS_PRICE  =  0.061205257667641046\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    pain(debug=debug, dropMissingValues=dropMissingValues, savePlots = savePlots, outlierThreshold = 3)\n",
    "    if debug == True:\n",
    "        debugFd.write(\"Module Completed...\\n\")\n",
    "        debugFd.write(lineString+\"\\n\")\n",
    "        debugFd.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e8776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6642685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc233c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
